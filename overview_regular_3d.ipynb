{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "classical-vaccine",
   "metadata": {},
   "source": [
    "# Getting an Overview of Regular 3D Data\n",
    "\n",
    "In this notebook, we're going to talk a little bit about how you might get an overview of regularized 3D data, specifically using matplotlib.\n",
    "\n",
    "In a subsequent notebook we'll address the next few steps, specifically how you might use tools like ipyvolume and yt.\n",
    "\n",
    "To start with, let's generate some fake data!  (Now, I say 'fake,' but that's a bit pejorative, isn't it?  Data is data!  Ours is just synthetic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-tulsa",
   "metadata": {},
   "source": [
    "We'll use the scipy [spherical harmonics](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.sph_harm.html) function to make some data, but first we need a reference coordinate system.  We'll start with $x, y, z$ and then transform them into spherical coordinates.\n",
    "\n",
    "**Note**: we'll be using the convention that $\\theta \\in [0, \\pi]$ and $\\phi \\in[0,2\\pi)$, which is reverse from what SciPy expects.  So if you compare to the docstring for sph_harm, keep that in mind.  Feel free to switch the definitions if you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "x = np.mgrid[-1.0:1.0:N*1j][:,None,None]\n",
    "y = np.mgrid[-1.0:1.0:N*1j][None,:,None]\n",
    "z = np.mgrid[-1.0:1.0:N*1j][None,None,:]\n",
    "\n",
    "r = np.sqrt(x*x + y*y + z*z)\n",
    "theta = np.arctan2(np.sqrt(x*x + y*y), z)\n",
    "phi = np.arctan2(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(x - r * np.sin(theta)*np.cos(phi)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(y - r * np.sin(theta)*np.sin(phi)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(z - r * np.cos(theta)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for n in [1, 4]:\n",
    "    for m in range(n + 1):\n",
    "        data[f\"sph_n{n}_m{m}\"] = np.absolute(scipy.special.sph_harm(m, n, phi, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-litigation",
   "metadata": {},
   "source": [
    "Now we have some data!  And, we can use matplotlib to visualize it in *reduced* form.  Let's try this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"sph_n4_m4\"][:,:,N//4], norm=LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi.min(), phi.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"sph_n1_m0\"].max(axis=0), norm=LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-mexican",
   "metadata": {},
   "source": [
    "This is getting a bit cumbersome, though!  Let's try using the [`ipywidgets`](https://ipywidgets.readthedocs.org) library to speed this up just a bit.\n",
    "\n",
    "We're going to use the `ipywidgets.interact` decorator around our function to add some inputs.  This is a pretty powerful decorator, as it sets up new widgets based on the info that you feed it, and then re-executes the function every time those inputs change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(dataset = list(sorted(data.keys())), slice_position = (0, N, 1))\n",
    "def make_plots(dataset, slice_position):\n",
    "    plt.imshow(data[dataset][slice_position,:,:], norm=LogNorm())\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-lewis",
   "metadata": {},
   "source": [
    "We still have some artifacts here we want to get rid of; let's see if we can restrict our colorbar a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(_.min() for _ in data.values()), max(_.max() for _ in data.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-gibraltar",
   "metadata": {},
   "source": [
    "Typically in these cases, the more interesting values are the ones at the top -- the bottom are usually falling off rather quickly to zero.  So let's set our maximum, and then drop 5 orders of magnitude for the minimum.  I'm changing the colorbar's \"extend\" value to reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(dataset = list(sorted(data.keys())), slice_position = (0, N, 1))\n",
    "def make_plots(dataset, slice_position):\n",
    "    plt.imshow(data[dataset][slice_position,:,:], norm=LogNorm(vmin=1e-5, vmax=1.0))\n",
    "    plt.colorbar(extend = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-interview",
   "metadata": {},
   "source": [
    "We're going to do one more thing for getting an overview, and then we'll see if we can do some other, cooler things with it using plotly.\n",
    "\n",
    "We're going to change our `slice_position` to be in units of actual coordinates, instead of integers, and we'll add on a multiplot so we can see all three at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(dataset = list(sorted(data.keys())), x = (-1.0, 1.0, 2.0/N), y = (-1.0, 1.0, 2.0/N), z = (-1.0, 1.0, 2.0/N))\n",
    "def make_plots(dataset, x, y, z):\n",
    "    xi, yi, zi = (int(_*N + 1.0) for _ in (x, y, z))\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, dpi = 200)\n",
    "    datax = data[dataset][xi,:,:]\n",
    "    datay = data[dataset][:,yi,:]\n",
    "    dataz = data[dataset][:,:,zi]\n",
    "    vmax = max(_.max() for _ in (datax, datay, dataz))\n",
    "    vmin = max( min(_.min() for _ in (datax, datay, dataz)), vmax / 1e5)\n",
    "    imx = axes[0][0].imshow(datax, norm=LogNorm(vmin=vmin, vmax=vmax), extent = [-1.0, 1.0, -1.0, 1.0])\n",
    "    imy = axes[0][1].imshow(datay, norm=LogNorm(vmin=vmin, vmax=vmax), extent = [-1.0, 1.0, -1.0, 1.0])\n",
    "    imz = axes[1][0].imshow(dataz, norm=LogNorm(vmin=vmin, vmax=vmax), extent = [-1.0, 1.0, -1.0, 1.0])\n",
    "    fig.delaxes(axes[1][1])\n",
    "    fig.colorbar(imx, ax=axes, extend = 'min', fraction = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"sph_n4_m3\"].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_data=go.Isosurface(\n",
    "    x=(x * np.ones((N,N,N))).flatten(),\n",
    "    y=(y * np.ones((N,N,N))).flatten(),\n",
    "    z=(z * np.ones((N,N,N))).flatten(),\n",
    "    value=data[\"sph_n4_m3\"].flatten(),\n",
    "    isomin=0,\n",
    "    isomax=data[\"sph_n4_m3\"].max(),\n",
    "    surface_count=5, # number of isosurfaces, 2 by default: only min and max\n",
    "    colorbar_nticks=5, # colorbar ticks correspond to isosurface values\n",
    "    caps=dict(x_show=False, y_show=False))\n",
    "fig = go.Figure(data = iso_data)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-orlando",
   "metadata": {},
   "source": [
    "One thing I've run into with plotly while making this notebook has been that in many cases, the 3D plots strain a bit under large data sizes.  This is to be expected, and is completely understandable!  One of the really nice things about regular mesh data like this is that you can usually cut it down quite effectively with slices.  Unfortunately, what I have found -- and I may have done something completely wrong! -- is that plotly some times appears to almost work, and then doesn't quite make it when I throw too much data at it.  I've found that it seems to work best in the neighborhood of $64^3$ zones, maybe a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-douglas",
   "metadata": {},
   "source": [
    "## Other Summary Techniques\n",
    "\n",
    "There are, of course, other ways you can take a look at a set of values!  Given a regular mesh, it's straightforward with numpy to apply any of the reduction operations along one of the axes.  For instance, you might take the min, the max, the sum, the mean and so forth.  If we do this with our spherical harmonics data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"sph_n4_m3\"].sum(axis=0), extent=[-1.0, 1.0, -1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-southwest",
   "metadata": {},
   "source": [
    "One thing you might keep in mind, when doing things like sums, is that if your cells aren't equally spaced along an axis, your sum will not necessarily be what you expect!  You may want to integrate instead, where you multiple by a path length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-statistics",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
